# Reconocimiento de entidad nombrada

Hasta ahora nos hemos concentrado principalmente en una tarea de PNL: la clasificaci√≥n. Sin embargo, tambi√©n existen otras tareas de PNL que se pueden realizar con redes neuronales. Una de esas tareas es **[Reconocimiento de entidad con nombre](https://wikipedia.org/wiki/Named-entity_recognition)** (NER), que se ocupa del reconocimiento de entidades espec√≠ficas dentro del texto, como lugares, nombres de personas, fechas. -intervalos de tiempo, f√≥rmulas qu√≠micas, etc.

## [Pre-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/119)

## Ejemplo de uso de NER

Suponga que desea desarrollar un bot de chat en lenguaje natural, similar a Amazon Alexa o Google Assistant. La forma en que funcionan los chatbots inteligentes es *comprender* lo que el usuario quiere clasificando el texto en la oraci√≥n de entrada. El resultado de esta clasificaci√≥n es la llamada **intenci√≥n**, que determina lo que debe hacer un chat bot.

<img alt="Bot NER" src="images/bot-ner.png" width="50%"/>

> Imagen del autor

Sin embargo, un usuario puede proporcionar algunos par√°metros como parte de la frase. Por ejemplo, cuando pregunta por el tiempo, puede especificar un lugar o una fecha. Un robot deber√≠a poder comprender esas entidades y completar los espacios de par√°metros en consecuencia antes de realizar la acci√≥n. Aqu√≠ es exactamente donde entra en juego NER.

> ‚úÖ Otro ejemplo ser√≠a [an√°lisis de art√≠culos m√©dicos cient√≠ficos] (https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). Una de las principales cosas que debemos buscar son t√©rminos m√©dicos espec√≠ficos, como enfermedades y sustancias m√©dicas. Si bien es probable que se pueda extraer una peque√±a cantidad de enfermedades mediante la b√∫squeda de subcadenas, entidades m√°s complejas, como compuestos qu√≠micos y nombres de medicamentos, necesitan un enfoque m√°s complejo.
>
> ## NER como clasificaci√≥n de tokens

Los modelos NER son esencialmente **modelos de clasificaci√≥n de tokens**, porque para cada uno de los tokens de entrada debemos decidir si pertenece a una entidad o no, y si es as√≠, a qu√© clase de entidad.

Considere el siguiente t√≠tulo del art√≠culo:

**Insuficiencia de la v√°lvula tric√∫spide** y **carbonato de litio** **toxicidad** en un reci√©n nacido.

Las entidades aqu√≠ son:

* La insuficiencia de la v√°lvula tric√∫spide es una enfermedad (`DIS`)
* El carbonato de litio es una sustancia qu√≠mica (`CHEM`)
* La toxicidad tambi√©n es una enfermedad (`DIS`)

Observe que una entidad puede abarcar varios tokens. Y, como en este caso, debemos distinguir entre dos entidades consecutivas. Por lo tanto, es com√∫n usar dos clases para cada entidad: una que especifica el primer token de la entidad (a menudo se usa el prefijo `B-`, para **b**comienzo) y otra, la continuaci√≥n de una entidad ( `I-`, para **i**nner token). Tambi√©n usamos `O` como clase para representar todos los **otros** tokens. Este etiquetado de tokens se denomina [etiquetado BIO](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (o IOB). Cuando est√© etiquetado, nuestro t√≠tulo se ver√° as√≠:

Ficha | Etiqueta
------|-----
Tric√∫spide | B-DIS
v√°lvula | I-DIS
regurgitaci√≥n | I-DIS
y | O
litio | B-CHEM
carbonato | I-CHEM
toxicidad | B-DIS
en | O
un | O
reci√©n nacido | O
infantil | O
. | O

Dado que necesitamos construir una correspondencia uno a uno entre tokens y clases, podemos entrenar un modelo de red neuronal **muchos a muchos** m√°s a la derecha a partir de esta imagen:

![Image showing common recurrent neural network patterns.](../17-GenerativeNetworks/images/unreasonable-effectiveness-of-rnn.jpg)

> *Imagen de [this blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) by [Andrej Karpathy](http://karpathy.github.io/). NER token classification models correspond to the right-most network architecture on this picture.*

## Entrenamiento de modelos NER

Dado que un modelo NER es esencialmente un modelo de clasificaci√≥n de tokens, podemos usar RNN con los que ya estamos familiarizados para esta tarea. En este caso, cada bloque de red recurrente devolver√° el ID del token. El siguiente cuaderno de ejemplo muestra c√≥mo entrenar LSTM para la clasificaci√≥n de tokens.

## ‚úçÔ∏è Cuadernos de ejemplo: NER

Contin√∫a tu aprendizaje en el siguiente cuaderno:

* [NER with TensorFlow](NER-TF.ipynb)

## Conclusi√≥n

Un modelo NER es un **modelo de clasificaci√≥n de tokens**, lo que significa que se puede utilizar para realizar una clasificaci√≥n de tokens. Esta es una tarea muy com√∫n en PNL y ayuda a reconocer entidades espec√≠ficas dentro del texto, incluidos lugares, nombres, fechas y m√°s.

## üöÄ Desaf√≠o

Complete la tarea vinculada a continuaci√≥n para entrenar un modelo de reconocimiento de entidades con nombre para t√©rminos m√©dicos y luego pru√©belo en un conjunto de datos diferente.

## [Post-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/219)

## Revisi√≥n y autoestudio

Leer el blog [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) y siga la secci√≥n de lecturas adicionales de ese art√≠culo para profundizar sus conocimientos.

## [Assignment](lab/README.md)

En la tarea de esta lecci√≥n, deber√° entrenar un modelo de reconocimiento de entidades m√©dicas. Puede comenzar entrenando un modelo LSTM como se describe en esta lecci√≥n y continuar usando el modelo de transformador BERT. Lea [las instrucciones](lab/README.md) para obtener todos los detalles.

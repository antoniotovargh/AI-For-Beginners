# codificadores autom√°ticos

Al entrenar CNN, uno de los problemas es que necesitamos muchos datos etiquetados. En el caso de la clasificaci√≥n de im√°genes, necesitamos separar las im√°genes en diferentes clases, lo cual es un esfuerzo manual.

## [Pre-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

Sin embargo, es posible que deseemos utilizar datos sin procesar (sin etiquetar) para entrenar extractores de funciones de CNN, lo que se denomina **aprendizaje autosupervisado**. En lugar de etiquetas, utilizaremos im√°genes de entrenamiento como entrada y salida de la red. La idea principal de **autoencoder** es que tendremos una **red codificadora** que convierte la imagen de entrada en alg√∫n **espacio latente** (normalmente es solo un vector de un tama√±o m√°s peque√±o), luego el **red decodificadora**, cuyo objetivo ser√≠a reconstruir la imagen original.

> ‚úÖ Un [autoencoder](https://wikipedia.org/wiki/Autoencoder) es "un tipo de red neuronal artificial utilizada para aprender codificaciones eficientes de datos sin etiquetar".
>
> Dado que estamos entrenando un codificador autom√°tico para capturar la mayor cantidad posible de informaci√≥n de la imagen original para una reconstrucci√≥n precisa, la red intenta encontrar la mejor **incrustaci√≥n** de im√°genes de entrada para capturar el significado.
>
> ![AutoEncoder Diagram](images/autoencoder_schema.jpg)

> Imagen de [Keras blog](https://blog.keras.io/building-autoencoders-in-keras.html)
>
> ## Escenarios para usar codificadores autom√°ticos

Si bien la reconstrucci√≥n de im√°genes originales no parece √∫til por s√≠ sola, existen algunos escenarios en los que los codificadores autom√°ticos son especialmente √∫tiles:

* **Reducir la dimensi√≥n de las im√°genes para visualizaci√≥n** o **entrenar incrustaciones de im√°genes**. Por lo general, los codificadores autom√°ticos dan mejores resultados que PCA porque tienen en cuenta la naturaleza espacial de las im√°genes y las caracter√≠sticas jer√°rquicas.
* **Eliminaci√≥n de ruido**, es decir, eliminaci√≥n del ruido de la imagen. Debido a que el ruido transporta una gran cantidad de informaci√≥n in√∫til, el codificador autom√°tico no puede caber todo en un espacio latente relativamente peque√±o y, por lo tanto, captura solo una parte importante de la imagen. Al entrenar eliminadores de ruido, comenzamos con im√°genes originales y usamos im√°genes con ruido agregado artificialmente como entrada para el codificador autom√°tico.
* **Superresoluci√≥n**, aumentando la resoluci√≥n de la imagen. Comenzamos con im√°genes de alta resoluci√≥n y usamos la imagen con menor resoluci√≥n como entrada del codificador autom√°tico.
* **Modelos generativos**. Una vez que entrenamos el codificador autom√°tico, la parte del decodificador se puede usar para crear nuevos objetos a partir de vectores latentes aleatorios.

## Autocodificadores variacionales (VAE)

Los codificadores autom√°ticos tradicionales reducen de alguna manera la dimensi√≥n de los datos de entrada, descubriendo las caracter√≠sticas importantes de las im√°genes de entrada. Sin embargo, los vectores latentes a menudo no tienen mucho sentido. En otras palabras, tomando como ejemplo el conjunto de datos MNIST, descubrir qu√© d√≠gitos corresponden a diferentes vectores latentes no es una tarea f√°cil, porque los vectores latentes cercanos no necesariamente corresponder√≠an a los mismos d√≠gitos.

Por otro lado, para entrenar modelos *generativos* es mejor tener cierto conocimiento del espacio latente. Esta idea nos lleva al **codificador autom√°tico variacional** (VAE).

VAE es el codificador autom√°tico que aprende a predecir la *distribuci√≥n estad√≠stica* de los par√°metros latentes, la llamada **distribuci√≥n latente**. Por ejemplo, es posible que deseemos que los vectores latentes se distribuyan normalmente con alguna media z<sub>media</sub> y desviaci√≥n est√°ndar z<sub>sigma</sub> (tanto la media como la desviaci√≥n est√°ndar son vectores de alguna dimensionalidad d). El codificador en VAE aprende a predecir esos par√°metros y luego el decodificador toma un vector aleatorio de esta distribuci√≥n para reconstruir el objeto.

Para resumir:

  * A partir del vector de entrada, predecimos `z_mean` y `z_log_sigma` (en lugar de predecir la desviaci√≥n est√°ndar en s√≠, predecimos su logaritmo)
  * Tomamos una muestra de un vector `muestra` de la distribuci√≥n N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
  * El decodificador intenta decodificar la imagen original usando `muestra` como vector de entrada

<img src="images/vae.png" width="50%">

> Imagen de [this blog post](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) by Isaak Dykeman

Los codificadores autom√°ticos variacionales utilizan una funci√≥n de p√©rdida compleja que consta de dos partes:

* **P√©rdida de reconstrucci√≥n** es la funci√≥n de p√©rdida que muestra qu√© tan cerca est√° una imagen reconstruida del objetivo (puede ser un error cuadr√°tico medio o MSE). Es la misma funci√≥n de p√©rdida que en los codificadores autom√°ticos normales.
* **P√©rdida de KL**, que garantiza que las distribuciones de variables latentes se mantengan cercanas a la distribuci√≥n normal. Se basa en la noci√≥n de [divergencia Kullback-Leibler](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained), una m√©trica para estimar qu√© tan similares son dos distribuciones estad√≠sticas. son.

Una ventaja importante de los VAE es que nos permiten generar nuevas im√°genes con relativa facilidad, porque sabemos de qu√© distribuci√≥n tomar muestras de vectores latentes. Por ejemplo, si entrenamos VAE con un vector latente 2D en MNIST, podemos variar los componentes del vector latente para obtener diferentes d√≠gitos:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> Imagen de [Dmitry Soshnikov](http://soshnikov.com)

Observe c√≥mo las im√°genes se mezclan entre s√≠, a medida que comenzamos a obtener vectores latentes de las diferentes partes del espacio de par√°metros latentes. Tambi√©n podemos visualizar este espacio en 2D:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> Imagen de [Dmitry Soshnikov](http://soshnikov.com)

## ‚úçÔ∏è Ejercicios: Autocodificadores

Obtenga m√°s informaci√≥n sobre los codificadores autom√°ticos en estos cuadernos correspondientes:

* [Autoencoders in TensorFlow](AutoencodersTF.ipynb)
* [Autoencoders in PyTorch](AutoEncodersPyTorch.ipynb)

## Propiedades de los codificadores autom√°ticos

* **Datos espec√≠ficos**: solo funcionan bien con el tipo de im√°genes en las que han sido entrenados. Por ejemplo, si entrenamos una red de superresoluci√≥n en flores, no funcionar√° bien en retratos. Esto se debe a que la red puede producir im√°genes de mayor resoluci√≥n al tomar detalles finos de las caracter√≠sticas aprendidas del conjunto de datos de entrenamiento.
* **Con p√©rdida**: la imagen reconstruida no es la misma que la imagen original. La naturaleza de la p√©rdida est√° definida por la *funci√≥n de p√©rdida* utilizada durante el entrenamiento
* Funciona con **datos sin etiqueta**

## [Post-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## Conclusi√≥n

En esta lecci√≥n, aprendi√≥ sobre los distintos tipos de codificadores autom√°ticos disponibles para el cient√≠fico de IA. Aprendiste c√≥mo construirlos y c√≥mo usarlos para reconstruir im√°genes. Tambi√©n aprendi√≥ sobre VAE y c√≥mo usarlo para generar nuevas im√°genes.

## üöÄ Desaf√≠o

En esta lecci√≥n, aprendi√≥ a usar codificadores autom√°ticos para im√°genes. ¬°Pero tambi√©n se pueden utilizar para m√∫sica! Consulte el proyecto [MusicVAE](https://magenta.tensorflow.org/music-vae) del proyecto Magenta, que utiliza codificadores autom√°ticos para aprender a reconstruir m√∫sica. Realice algunos [experimentos](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) con esta biblioteca para ver qu√© puede crear.

## [Post-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Review & Self Study

For reference, read more about autoencoders in these resources:

* [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Blog post on NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Variational Autoencoders Explained](https://kvfrans.com/variational-autoencoders-explained/)
* [Conditional Variational Autoencoders](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Asignaci√≥n

Al final de [this notebook using TensorFlow](AutoencodersTF.ipynb), encontrar√° una 'tarea'; util√≠cela como su tarea.

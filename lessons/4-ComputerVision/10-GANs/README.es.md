# Redes generativas de confrontaci√≥n

En la secci√≥n anterior, aprendimos sobre los **modelos generativos**: modelos que pueden generar nuevas im√°genes similares a las del conjunto de datos de entrenamiento. VAE fue un buen ejemplo de modelo generativo.

## [Pre-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

Sin embargo, si intentamos generar algo realmente significativo, como una pintura con una resoluci√≥n razonable, con VAE, veremos que el entrenamiento no converge bien. Para este caso de uso, deber√≠amos conocer otra arquitectura dirigida espec√≠ficamente a modelos generativos: **Redes generativas adversas** o GAN.

La idea principal de una GAN es tener dos redes neuronales que se entrenar√°n entre s√≠:

<img src="images/gan_architecture.png" width="70%"/>

> Imagen de [Dmitry Soshnikov](http://soshnikov.com)

> ‚úÖ Un poco de vocabulario:
> * **Generador** es una red que toma alg√∫n vector aleatorio y produce la imagen como resultado
> * **Discriminator** es una red que toma una imagen y debe indicar si es una imagen real (del conjunto de datos de entrenamiento) o si fue generada por un generador. Es esencialmente un clasificador de im√°genes.

### Discriminador

La arquitectura del discriminador no difiere de la de una red de clasificaci√≥n de im√°genes ordinaria. En el caso m√°s simple, puede ser un clasificador completamente conectado, pero lo m√°s probable es que sea una [red convolucional] (../07-ConvNets/README.md).

> ‚úÖ Una GAN basada en redes convolucionales se llama [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

Un discriminador CNN consta de las siguientes capas: varias convoluciones + agrupaciones (con tama√±o espacial decreciente) y una o m√°s capas completamente conectadas para obtener el "vector de caracter√≠sticas", clasificador binario final.

> ‚úÖ Un 'pooling' en este contexto es una t√©cnica que reduce el tama√±o de la imagen. "La agrupaci√≥n de capas reduce las dimensiones de los datos al combinar las salidas de los grupos de neuronas en una capa en una sola neurona en la siguiente capa". - [fuente](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Generador

Un generador es un poco m√°s complicado. Puedes considerarlo como un discriminador inverso. A partir de un vector latente (en lugar de un vector de caracter√≠sticas), tiene una capa completamente conectada para convertirla al tama√±o/forma requerido, seguida de deconvoluciones + ampliaci√≥n de escala. Esto es similar a la parte *decodificador* de [autoencoder](../09-Autoencoders/README.md).

> ‚úÖ Debido a que la capa de convoluci√≥n se implementa como un filtro lineal que atraviesa la imagen, la deconvoluci√≥n es esencialmente similar a la convoluci√≥n y se puede implementar usando la misma l√≥gica de capa.

<img src="images/gan_arch_detail.png" width="70%"/>

> Imagen de [Dmitry Soshnikov](http://soshnikov.com)

### Entrenando la GAN

Las GAN se denominan **adversarias** porque existe una competencia constante entre el generador y el discriminador. Durante esta competencia, tanto el generador como el discriminador mejoran, por lo que la red aprende a producir cada vez mejores im√°genes.

La formaci√≥n se desarrolla en dos etapas:

* **Entrenando al discriminador**. Esta tarea es bastante sencilla: generamos un lote de im√°genes mediante el generador, las etiquetamos con 0, que significa imagen falsa, y tomamos un lote de im√°genes del conjunto de datos de entrada (con etiqueta 1, imagen real). Obtenemos algo de *p√©rdida de discriminador* y realizamos backprop.
* **Entrenamiento del generador**. Esto es un poco m√°s complicado, porque no conocemos directamente la salida esperada del generador. Tomamos toda la red GAN que consta de un generador seguido de un discriminador, la alimentamos con algunos vectores aleatorios y esperamos que el resultado sea 1 (correspondiente a im√°genes reales). Luego congelamos los par√°metros del discriminador (no queremos que se entrene en este paso) y realizamos la backprop.

Durante este proceso, las p√©rdidas tanto del generador como del discriminador no disminuyen significativamente. En la situaci√≥n ideal deber√≠an oscilar, correspondiendo a que ambas redes mejoren su rendimiento.

## ‚úçÔ∏è Ejercicios: GAN 

* [GAN Notebook in TensorFlow/Keras](GANTF.ipynb)
* [GAN Notebook in PyTorch](GANPyTorch.ipynb)

### Problemas con el entrenamiento GAN

Se sabe que las GAN son especialmente dif√≠ciles de entrenar. Aqu√≠ hay algunos problemas:

* **Modo Colapso**. Con este t√©rmino queremos decir que el generador aprende a producir una imagen exitosa que enga√±a al generador, y no una variedad de im√°genes diferentes.
* **Sensibilidad a los hiperpar√°metros**. A menudo se puede ver que una GAN no converge en absoluto y luego, repentinamente, la tasa de aprendizaje disminuye, lo que conduce a la convergencia.
* Mantener un **equilibrio** entre el generador y el discriminador. En muchos casos, la p√©rdida del discriminador puede caer a cero con relativa rapidez, lo que provoca que el generador no pueda seguir entren√°ndose. Para superar esto, podemos intentar establecer diferentes tasas de aprendizaje para el generador y el discriminador, u omitir el entrenamiento del discriminador si la p√©rdida ya es demasiado baja.
* Entrenamiento para **alta resoluci√≥n**. Reflejando el mismo problema que con los codificadores autom√°ticos, este problema se desencadena porque la reconstrucci√≥n de demasiadas capas de red convolucional genera artefactos. Este problema generalmente se resuelve con el llamado **crecimiento progresivo**, cuando primero se entrenan algunas capas en im√°genes de baja resoluci√≥n y luego se "desbloquean" o agregan capas. Otra soluci√≥n ser√≠a agregar conexiones adicionales entre capas y entrenar varias resoluciones a la vez; consulte este [art√≠culo sobre GAN de gradiente multiescala] (https://arxiv.org/abs/1903.06048) para obtener m√°s detalles.

## Transferencia de estilo

Las GAN son una excelente manera de generar im√°genes art√≠sticas. Otra t√©cnica interesante es la llamada **transferencia de estilo**, que toma una **imagen de contenido** y la vuelve a dibujar en un estilo diferente, aplicando filtros de **imagen de estilo**.

La forma en que funciona es la siguiente:
* Comenzamos con una imagen de ruido aleatorio (o con una imagen de contenido, pero para facilitar la comprensi√≥n es m√°s f√°cil comenzar con ruido aleatorio)
* Nuestro objetivo ser√≠a crear una imagen de este tipo, que se acerque tanto a la imagen de contenido como a la imagen de estilo. Esto estar√≠a determinado por dos funciones de p√©rdida:
    - La **p√©rdida de contenido** se calcula en funci√≥n de las caracter√≠sticas extra√≠das por CNN en algunas capas de la imagen actual y la imagen del contenido.
    - La **p√©rdida de estilo** se calcula entre la imagen actual y la imagen de estilo de una manera inteligente utilizando matrices de Gram (m√°s detalles en el [example notebook](StyleTransfer.ipynb))
* Para suavizar la imagen y eliminar el ruido, tambi√©n introducimos la **P√©rdida de variaci√≥n**, que calcula la distancia promedio entre p√≠xeles vecinos.
* El bucle de optimizaci√≥n principal ajusta la imagen actual mediante el descenso de gradiente (o alg√∫n otro algoritmo de optimizaci√≥n) para minimizar la p√©rdida total, que es una suma ponderada de las tres p√©rdidas.

## ‚úçÔ∏è Ejemplo: [Style Transfer](StyleTransfer.ipynb)

## [Post-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## Conclusi√≥n

En esta lecci√≥n, aprendiste sobre GANS y c√≥mo entrenarlos. Tambi√©n aprendi√≥ sobre los desaf√≠os especiales que puede enfrentar este tipo de red neuronal y algunas estrategias sobre c√≥mo superarlos.

## üöÄ Desaf√≠o

Corre por el [Style Transfer notebook](StyleTransfer.ipynb) usando tus propias im√°genes. 

## Revisi√≥n y autoestudio

Como referencia, lea m√°s sobre las GAN en estos recursos:

* Marco Pasini, [10 Lessons I Learned Training GANs for one Year](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), a *de facto* GAN arquitectura a considerar
* [Creating Generative Art using GANs on Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Asignaci√≥n

Vuelva a visitar uno de los dos cuadernos asociados a esta lecci√≥n y vuelva a entrenar la GAN con sus propias im√°genes. ¬øQu√© puedes crear?

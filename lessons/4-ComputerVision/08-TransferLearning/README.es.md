# Pre-trained Networks and Transfer Learning

Training CNNs can take a lot of time, and a lot of data is required for that task. However, much of the time is spent learning the best low-level filters that a network can use to extract patterns from images. A natural question arises - can we use a neural network trained on one dataset and adapt it to classify different images without requiring a full training process?

## [Pre-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/108)

Este enfoque se llama **aprendizaje por transferencia** porque transferimos algunos conocimientos de un modelo de red neuronal a otro. En el aprendizaje por transferencia, normalmente comenzamos con un modelo previamente entrenado, que ha sido entrenado en alg√∫n conjunto de datos de im√°genes grande, como **ImageNet**. Esos modelos ya pueden hacer un buen trabajo extrayendo diferentes caracter√≠sticas de im√°genes gen√©ricas y, en muchos casos, simplemente construir un clasificador sobre esas caracter√≠sticas extra√≠das puede producir un buen resultado.

> ‚úÖ Transfer Learning es un t√©rmino que se encuentra en otros campos acad√©micos, como la Educaci√≥n. Se refiere al proceso de tomar conocimiento de un dominio y aplicarlo a otro.

## Modelos previamente entrenados como extractores de caracter√≠sticas

Las redes convolucionales de las que hemos hablado en la secci√≥n anterior conten√≠an una serie de capas, cada una de las cuales se supone que extrae algunas caracter√≠sticas de la imagen, comenzando desde combinaciones de p√≠xeles de bajo nivel (como una l√≠nea o trazo horizontal/vertical), hasta a combinaciones de caracter√≠sticas de nivel superior, correspondientes a cosas como el ojo de una llama. Si entrenamos a CNN con un conjunto de datos suficientemente grande de im√°genes gen√©ricas y diversas, la red deber√≠a aprender a extraer esas caracter√≠sticas comunes.

Tanto Keras como PyTorch contienen funciones para cargar f√°cilmente pesos de redes neuronales previamente entrenados para algunas arquitecturas comunes, la mayor√≠a de las cuales fueron entrenadas en im√°genes de ImageNet. Los m√°s utilizados se describen en la p√°gina [Arquitecturas CNN](../07-ConvNets/CNN_Architectures.md) de la lecci√≥n anterior. En particular, es posible que desee considerar el uso de uno de los siguientes:

* **VGG-16/VGG-19** que son modelos relativamente simples que a√∫n ofrecen buena precisi√≥n. A menudo, utilizar VGG como primer intento es una buena opci√≥n para ver c√≥mo funciona el aprendizaje por transferencia.
* **ResNet** es una familia de modelos propuesta por Microsoft Research en 2015. Tienen m√°s capas y, por lo tanto, requieren m√°s recursos.
* **MobileNet** es una familia de modelos de tama√±o reducido, aptos para dispositivos m√≥viles. √öselos si tiene pocos recursos y puede sacrificar un poco de precisi√≥n.

Aqu√≠ hay ejemplos de caracter√≠sticas extra√≠das de una imagen de un gato por la red VGG-16:

![Features extracted by VGG-16](images/features.png)

## Conjunto de datos sobre gatos y perros

En este ejemplo, usaremos un conjunto de datos de [Cats and Dogs](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), which is very close to a real-life image classification scenario.

## ‚úçÔ∏è Exercise: Transfer Learning

Let's see transfer learning in action in corresponding notebooks:

* [Transfer Learning - PyTorch](TransferLearningPyTorch.ipynb)
* [Transfer Learning - TensorFlow](TransferLearningTF.ipynb)

## Visualizando al gato adversario

La red neuronal previamente entrenada contiene diferentes patrones dentro de su *cerebro*, incluidas nociones de **gato ideal** (as√≠ como de perro ideal, cebra ideal, etc.). Ser√≠a interesante de alguna manera **visualizar esta imagen**. Sin embargo, no es sencillo, porque los patrones est√°n repartidos por todos los pesos de la red y tambi√©n organizados en una estructura jer√°rquica.

Un enfoque que podemos tomar es comenzar con una imagen aleatoria y luego intentar usar la t√©cnica de **optimizaci√≥n de descenso de gradiente** para ajustar esa imagen de tal manera que la red comience a pensar que es un gato.

![Image Optimization Loop](images/ideal-cat-loop.png)

Sin embargo, si hacemos esto, recibiremos algo muy similar a un ruido aleatorio. Esto se debe a que *hay muchas maneras de hacer que la red piense que la imagen de entrada es un gato*, incluidas algunas que no tienen sentido visualmente. Si bien esas im√°genes contienen muchos patrones t√≠picos de un gato, no hay nada que las limite a ser visualmente distintivas.

Para mejorar el resultado, podemos agregar otro t√©rmino a la funci√≥n de p√©rdida, que se llama **p√©rdida de variaci√≥n**. Es una m√©trica que muestra qu√© tan similares son los p√≠xeles vecinos de la imagen. Minimizar la p√©rdida de variaci√≥n hace que la imagen sea m√°s suave y elimina el ruido, revelando as√≠ patrones m√°s atractivos visualmente. A continuaci√≥n se muestra un ejemplo de im√°genes "ideales" que se clasifican como gatos y cebras con alta probabilidad:

![Ideal Cat](images/ideal-cat.png) | ![Ideal Zebra](images/ideal-zebra.png)
-----|-----
 *Ideal Cat* | *Ideal Zebra*

 Se puede utilizar un enfoque similar para realizar los llamados **ataques adversarios** en una red neuronal. Supongamos que queremos enga√±ar a una red neuronal y hacer que un perro parezca un gato. Si tomamos la imagen del perro, que una red reconoce como un perro, podemos modificarla un poco pero usando la optimizaci√≥n de descenso de gradiente, hasta que la red comience a clasificarlo como un gato:

 ![Picture of a Dog](images/original-dog.png) | ![Picture of a dog classified as a cat](images/adversarial-dog.png)
-----|-----
*Imagen original de un perro* | *Foto de un perro clasificado como gato*

Vea el c√≥digo para reproducir los resultados anteriores en el siguiente cuaderno:

* [Ideal and Adversarial Cat - TensorFlow](AdversarialCat_TF.ipynb)
## Conclusion

Al utilizar el aprendizaje por transferencia, puede crear r√°pidamente un clasificador para una tarea de clasificaci√≥n de objetos personalizada y lograr una alta precisi√≥n. Puede ver que las tareas m√°s complejas que estamos resolviendo ahora requieren una mayor potencia computacional y no se pueden resolver f√°cilmente en la CPU. En la siguiente unidad, intentaremos utilizar una implementaci√≥n m√°s ligera para entrenar el mismo modelo utilizando menores recursos inform√°ticos, lo que da como resultado una precisi√≥n ligeramente menor.

## üöÄ Desaf√≠o

En los cuadernos adjuntos, hay notas al final sobre c√≥mo funciona mejor la transferencia de conocimientos con datos de entrenamiento algo similares (un nuevo tipo de animal, tal vez). Experimente un poco con tipos de im√°genes completamente nuevos para ver qu√© tan bien o mal funcionan sus modelos de transferencia de conocimiento.

## [Post-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Revisi√≥n y autoestudio

Leer de parte a parte [TrainingTricks.md](TrainingTricks.md) para profundizar su conocimiento sobre alguna otra forma de entrenar sus modelos.

## [Assignment](lab/README.md)

En este laboratorio, usaremos la vida real [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) conjunto de datos de mascotas con 35 razas de perros y gatos, y crearemos un clasificador de aprendizaje por transferencia.

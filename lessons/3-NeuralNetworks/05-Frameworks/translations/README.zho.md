# 神经网络框架

正如我们已经学到的，要想高效地训练神经网络，我们需要做两件事：

* 对张量进行操作，如乘法、加法和计算一些函数，如 sigmoid 或 softmax。
* 计算所有表达式的梯度，以便进行梯度下降优化

## [课前测验](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/105)

虽然 "numpy "库可以完成第一部分，但我们需要一些机制来计算梯度。在上一节我们开发的[我们的框架](../../04-OwnFramework/OwnFramework.ipynb)中，我们不得不手动将所有导数函数编入 "backward "方法中，该方法进行反向传播。理想情况下，一个框架应该让我们有机会计算我们可以定义的*任何表达式*的梯度。

还有一点很重要，那就是能够在 GPU 或任何其他专用计算单元上执行计算，例如 [TPU](https://en.wikipedia.org/wiki/Tensor_Processing_Unit)。深度神经网络训练需要*大量*的计算，能够在 GPU 上并行处理这些计算非常重要。

> ✅"并行化 "一词的意思是将计算分配到多个设备上。

目前，最流行的两个神经框架是 [TensorFlow](http://TensorFlow.org)和[PyTorch](https://pytorch.org/)。两者都提供了底层应用程序接口，可在 CPU 和 GPU 上对张量进行操作。在底层 API 的基础上，还有更高层次的 API，分别称为 [Keras](https://keras.io/) 和 [PyTorch Lightning](https://pytorchlightning.ai/)。

低级 API | [TensorFlow](http://TensorFlow.org) | [PyTorch](https://pytorch.org/)
--------------|-------------------------------------|--------------------------------
高级 API| [Keras](https://keras.io/) | [PyTorch Lightning](https://pytorchlightning.ai/)

这两个框架中的**低级应用程序接口**允许您构建所谓的**计算图**。该图定义了如何在给定输入参数的情况下计算输出（通常是损失函数），如果 GPU 可用，还可以推送到 GPU 上进行计算。有一些函数可以区分这种计算图并计算梯度，然后用于优化模型参数。

**高级应用程序接口**几乎将神经网络视为**层序列**，使大部分神经网络的构建变得更加容易。训练模型通常需要准备数据，然后调用 "fit "函数来完成这项工作。

高级应用程序接口允许您快速构建典型的神经网络，而无需担心大量细节。同时，低级 API 对训练过程的控制能力更强，因此在研究新的神经网络架构时，低级 API 被大量使用。

同样重要的是，你可以同时使用这两种应用程序接口，例如，你可以使用低级应用程序接口开发自己的网络层架构，然后在使用高级应用程序接口构建和训练的大型网络中使用它。或者，你也可以使用高级 API 将网络定义为一个层序列，然后使用自己的低级训练循环来执行优化。这两种应用程序接口使用相同的基本概念，而且可以很好地协同工作。

## 学习

在本课程中，我们提供了 PyTorch 和 TensorFlow 的大部分内容。您可以选择自己喜欢的框架，然后只浏览相应的笔记本。如果您不确定选择哪种框架，可以阅读互联网上关于 **PyTorch 与 TensorFlow 的讨论。你也可以看看这两个框架，以便更好地理解。

为了简单起见，我们将尽可能使用高级应用程序接口。不过，我们认为从基础开始了解神经网络的工作原理非常重要，因此一开始我们会使用底层 API 和张量。不过，如果你想快速入门，不想花大量时间学习这些细节，可以跳过这些内容，直接进入高级 API 笔记本。

## ✍️ 练习： 框架

在以下笔记本中继续学习：

低级 API | [TensorFlow+Keras Notebook](../IntroKerasTF.ipynb) | [PyTorch](../IntroPyTorch.ipynb)
--------------|-------------------------------------|--------------------------------
高级 API| [Keras](../IntroKeras.ipynb)| *PyTorch Lightning*

掌握了框架之后，让我们来回顾一下过度拟合的概念。

# 过度拟合

过拟合是机器学习中一个极其重要的概念，正确理解它非常重要！

请看下面这个近似 5 个点（在下图中用 `x` 表示）的问题：

![linear](../../images/overfit1.jpg) | ![overfit](../../images/overfit2.jpg)
-------------------------|--------------------------
**线性模型，2 个参数** | **线性模型，7 个参数**
训练误差 = 5.3 | 训练误差 = 0
验证误差 = 5.1 | 验证误差 = 20

* 在左边，我们看到了一个很好的直线近似值。由于参数数量足够，该模型正确地表达了点分布的概念。
* 右边的模型过于强大。因为我们只有 5 个点，而模型有 7 个参数，所以它可以调整到通过所有点，使训练误差为 0。

在模型的丰富度（参数数量）和训练样本数量之间取得正确的平衡非常重要。

## 为何会出现过拟合

  * 训练数据不足
  * 模型太强大
  * 输入数据中噪音太大

## 如何检测过度拟合

从上图可以看出，过度拟合可以通过很低的训练误差和很高的验证误差检测出来。通常在训练过程中，我们会看到训练误差和验证误差都开始下降，然后在某个时刻验证误差可能会停止下降并开始上升。这就是过拟合的迹象，表明我们可能应该在此时停止训练（或至少对模型进行快照）。

![overfitting](../../images/Overfitting.png)

## 如何防止过度拟合

如果发现过度拟合现象，可以采取以下措施之一：

 * 增加训练数据量
 * 降低模型的复杂度
 * 使用一些[正则化技术](.../.../4-ComputerVision/08-TransferLearning/TrainingTricks.md)，例如[Dropout](.../../4-ComputerVision/08-TransferLearning/TrainingTricks.md#Dropout)，我们稍后会考虑它。

## 过度拟合与偏差-方差权衡

过度拟合实际上是统计学中一个更普遍的问题的一种情况，称为[偏差-方差权衡](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)。如果我们考虑模型中可能的误差来源，我们可以看到两种类型的误差：

* 偏差错误***是由于我们的算法无法正确捕捉训练数据之间的关系造成的。这可能是由于我们的模型不够强大（**拟合不足**）。
**方差误差**，是由于模型逼近输入数据中的噪声而不是有意义的关系（**过拟合**）造成的。

在训练过程中，偏差误差会减小（因为我们的模型学会了逼近数据），而方差误差会增大。重要的是要手动（当我们检测到过拟合时）或自动（通过引入正则化）停止训练，以防止过拟合。

## 结论

在本课中，您了解了两个最流行的人工智能框架 TensorFlow 和 PyTorch 的各种 API 之间的差异。此外，你还了解了一个非常重要的话题--过度拟合。

## 🚀 挑战

在随附的笔记本中，您会发现底部有 "任务"；请阅读笔记本并完成任务。

## [课后测验](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/205)

### 复习与自学

就以下主题做一些研究：

- TensorFlow
- PyTorch
- Overfitting

问自己以下问题

- TensorFlow 和 PyTorch 有什么区别？
- 过度拟合和欠拟合有什么区别？

## [作业](../lab/README.md)

在本实验中，要求你使用 PyTorch 或 TensorFlow，使用单层和多层全连接网络解决两个分类问题。

* [Instructions](../lab/README.md)
* [Notebook](../lab/LabFrameworks.ipynb)
